% Encoding: UTF-8

@Article{pericchiTorres2011,
  author    = {Luis Pericchi and David Torres},
  title     = {Quick anomaly detection by the {N}ewcomb—{B}enford law, with applications to electoral processes data from the {USA}, {P}uerto {R}ico and {V}enezuela},
  journal   = {Statistical Science},
  year      = {2011},
  volume    = {26},
  number    = {4},
  pages     = {502--516},
  abstract  = {A simple and quick general test to screen for numerical anomalies is presented. It can be applied, for example, to electoral processes, both electronic and manual. It uses vote counts in officially published voting units, which are typically widely available and institutionally backed. The test examines the frequencies of digits on voting counts and rests on the First (NBL1) and Second Digit Newcomb—Benford Law (NBL2), and in a novel generalization of the law under restrictions of the maximum number of voters per unit (RNBL2). We apply the test to the 2004 USA presidential elections, the Puerto Rico (1996, 2000 and 2004) governor elections, the 2004 Venezuelan presidential recall referendum (RRP) and the previous 2000 Venezuelan Presidential election. The NBL2 is compellingly rejected only in the Venezuelan referendum and only for electronic voting units. Our original suggestion on the RRP (Pericchi and Torres, 2004) was criticized by The Carter Center report (2005). Acknowledging this, Mebane (2006) and The Economist (US) (2007) presented voting models and case studies in favor of NBL2. Further evidence is presented here. Moreover, under the RNBL2, Mebane's voting models are valid under wider conditions. The adequacy of the law is assessed through Bayes Factors (and corrections of p-values) instead of significance testing, since for large sample sizes and fixed α levels the null hypothesis is over rejected. Our tests are extremely simple and can become a standard screening that a fair electoral process should pass.},
  file      = {:/Users/pedrofonseca/Documents/Artigos e Teses/Pericchi and Torres (2011).pdf:PDF},
  groups    = {Digit Analysis},
  publisher = {Institute of Mathematical Statistics},
}

@Article{kass1995,
  author    = {Robert E. Kass and Adrian E. Raftery},
  title     = {Bayes factors},
  journal   = {Journal of the American Statistical Association},
  year      = {1995},
  volume    = {90},
  number    = {430},
  pages     = {773--795},
  abstract  = { Abstract In a 1935 paper and in his book Theory of Probability, Jeffreys developed a methodology for quantifying the evidence in favor of a scientific theory. The centerpiece was a number, now called the Bayes factor, which is the posterior odds of the null hypothesis when the prior probability on the null is one-half. Although there has been much discussion of Bayesian hypothesis testing in the context of criticism of P-values, less attention has been given to the Bayes factor as a practical tool of applied statistics. In this article we review and discuss the uses of Bayes factors in the context of five scientific applications in genetics, sports, ecology, sociology, and psychology. We emphasize the following points: • From Jeffreys' Bayesian viewpoint, the purpose of hypothesis testing is to evaluate the evidence in favor of a scientific theory. • Bayes factors offer a way of evaluating evidence in favor of a null hypothesis. • Bayes factors provide a way of incorporating external information into the evaluation of evidence about a hypothesis. • Bayes factors are very general and do not require alternative models to be nested. • Several techniques are available for computing Bayes factors, including asymptotic approximations that are easy to compute using the output from standard packages that maximize likelihoods. • In “nonstandard” statistical models that do not satisfy common regularity conditions, it can be technically simpler to calculate Bayes factors than to derive non-Bayesian significance tests. • The Schwarz criterion (or BIC) gives a rough approximation to the logarithm of the Bayes factor, which is easy to use and does not require evaluation of prior distributions. • When one is interested in estimation or prediction, Bayes factors may be converted to weights to be attached to various models so that a composite estimate or prediction may be obtained that takes account of structural or model uncertainty. • Algorithms have been proposed that allow model uncertainty to be taken into account when the class of models initially considered is very large. • Bayes factors are useful for guiding an evolutionary model-building process. • It is important, and feasible, to assess the sensitivity of conclusions to the prior distributions used. },
  file      = {:/Users/pedrofonseca/Documents/Artigos e Teses/Kass and Raftery (1995).pdf:PDF},
  publisher = {Taylor \& Francis},
}